<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>开放词汇视觉感知 | 半夏琉璃空</title><meta name="author" content="听灵"><meta name="copyright" content="听灵"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="2024.6.2  本周:学习了开放词汇的思想概念,并针对开放词汇分类和部分开放词汇检测模型检索学习主体框架思想. 下周预期目标:继续学习开放词汇检测模型和了解学习词汇分割(之前没接触过这一部分)  2024.6.7  本周：对经典模型clp论文研读，巩固强化了解语言模型，继续粗读了几种开放词汇检测模型 下周：学习了解之前所粗看的模型的一些不懂的知识和词汇  报告链接分享 背景介绍 传统视觉感知模">
<meta property="og:type" content="article">
<meta property="og:title" content="开放词汇视觉感知">
<meta property="og:url" content="http://example.com/2024/05/28/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/index.html">
<meta property="og:site_name" content="半夏琉璃空">
<meta property="og:description" content="2024.6.2  本周:学习了开放词汇的思想概念,并针对开放词汇分类和部分开放词汇检测模型检索学习主体框架思想. 下周预期目标:继续学习开放词汇检测模型和了解学习词汇分割(之前没接触过这一部分)  2024.6.7  本周：对经典模型clp论文研读，巩固强化了解语言模型，继续粗读了几种开放词汇检测模型 下周：学习了解之前所粗看的模型的一些不懂的知识和词汇  报告链接分享 背景介绍 传统视觉感知模">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ts1.cn.mm.bing.net/th/id/R-C.ee3ad0b69428b46be2c9e30317db058f?rik=JV94iKBiuWCNJg&riu=http%3a%2f%2fpic.bizhi360.com%2fbbpic%2f27%2f2727.jpg&ehk=c2AYatSYzhHx3oUBzqSvzhTD62o7hz6mF5TBHt4nlQ8%3d&risl=&pid=ImgRaw&r=0">
<meta property="article:published_time" content="2024-05-28T02:54:32.000Z">
<meta property="article:modified_time" content="2024-06-09T12:29:49.240Z">
<meta property="article:author" content="听灵">
<meta property="article:tag" content="深度学习|计算机视觉|多模态大模型">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ts1.cn.mm.bing.net/th/id/R-C.ee3ad0b69428b46be2c9e30317db058f?rik=JV94iKBiuWCNJg&riu=http%3a%2f%2fpic.bizhi360.com%2fbbpic%2f27%2f2727.jpg&ehk=c2AYatSYzhHx3oUBzqSvzhTD62o7hz6mF5TBHt4nlQ8%3d&risl=&pid=ImgRaw&r=0"><link rel="shortcut icon" href="/images/041_%E6%98%9F%E7%90%83.png"><link rel="canonical" href="http://example.com/2024/05/28/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="/-apple-system,Lato" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体中文","cht_to_chs":"你已切换为简体中文","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '开放词汇视觉感知',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-06-09 20:29:49'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="/css/universe.css"><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 7.1.1"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/%E7%AB%A5%E5%BF%83%E4%B9%8B%E4%B9%A6.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://ts1.cn.mm.bing.net/th/id/R-C.ee3ad0b69428b46be2c9e30317db058f?rik=JV94iKBiuWCNJg&amp;riu=http%3a%2f%2fpic.bizhi360.com%2fbbpic%2f27%2f2727.jpg&amp;ehk=c2AYatSYzhHx3oUBzqSvzhTD62o7hz6mF5TBHt4nlQ8%3d&amp;risl=&amp;pid=ImgRaw&amp;r=0')"><nav id="nav"><span id="blog-info"><a href="/" title="半夏琉璃空"><span class="site-name">半夏琉璃空</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">开放词汇视觉感知</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-05-28T02:54:32.000Z" title="发表于 2024-05-28 10:54:32">2024-05-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-06-09T12:29:49.240Z" title="更新于 2024-06-09 20:29:49">2024-06-09</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="开放词汇视觉感知"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>2024.6.2</p>
<ul>
<li>本周:学习了开放词汇的思想概念,并针对开放词汇分类和部分开放词汇检测模型检索学习主体框架思想.</li>
<li>下周预期目标:继续学习开放词汇检测模型和了解学习词汇分割(之前没接触过这一部分)</li>
</ul>
<p>2024.6.7</p>
<ul>
<li>本周：对经典模型clp论文研读，巩固强化了解语言模型，继续粗读了几种开放词汇检测模型</li>
<li>下周：学习了解之前所粗看的模型的一些不懂的知识和词汇</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://b23.tv/err4EvJ?share_medium=android&amp;share_source=qq&amp;bbid=XY8675383E088DF9060D7760F32782495A44E&amp;ts=1716510410958">报告链接分享</a></p>
<h1 id="背景介绍">背景介绍</h1>
<p>传统视觉感知模型在开放场景中，无法完成对陌生类别的正确识别</p>
<p>对于开放场景的多种任务类型</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/mul_task.png" alt="为应对开放场景中的挑战，多种任务类型被提出"></p>
<h2 id="open-set-recognition">open-Set Recognition</h2>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1812.04246v2">论文原文</a></p>
<ul>
<li>
<p>训练集中的类别和测试集中的类别是一致的，最常见的就是使用公开数据集进行训练，所有数据集中的图像的类别都是已知的，没有未知种类的图像。传统的机器学习的算法在这些任务上已经取得了比较好的效果。</p>
</li>
<li>
<p>现实场景中更多的是开放和非静态的环境，比如，一些没有见过的情况会意外出现。</p>
</li>
<li>
<p>开集识别简单定义是，一个在训练集上训练好的模型，当利用一个测试集（该测试集的中包含训练集中没有的类别）进行测试时，如果输入已知类别数据，输出具体的类别，如果输入的是未知类别的数据，则进行合适的处理（识别为unknown）。</p>
</li>
<li>
<p>示例 :</p>
<ul>
<li>猫狗识别模型，输入一张荷花或者大象的图像，模型可能会告诉你80% 的概率为 猫。</li>
<li>想要的结果 : 输入不为猫狗的图像，模型输出为未知类别，输入猫狗图像，模型输出对应具体的类别</li>
</ul>
</li>
</ul>
<h2 id="few-shot-learning">Few-Shot Learning</h2>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.05046">该文章总结166篇参考文献阐述了什么是少样本学习</a></p>
<p>整体主题</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/FSL.png" alt=""></p>
<ul>
<li>利用先验知识从数据,模型,算法角度处理问题</li>
</ul>
<h2 id="zero-shot-learning">Zero-Shot Learning</h2>
<p><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/abs/10.1145/3293318">完整介绍</a></p>
<ul>
<li>简单阐述,零样本学习就是，在测试集中，有些类别不在训练集中，利用训练集的样本训练一个模型，使之应用到测试集能正确识别那些在训练集中不存在的标签。</li>
</ul>
<h2 id="open-vocabulary-learning">Open Vocabulary Learning</h2>
<ul>
<li>核心为从大规模数据提炼知识，并迁移到下游感知任务</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/vac.png" alt=""></p>
<h1 id="开放词汇分类">开放词汇分类</h1>
<ul>
<li>基本原理：利用海量图像-文本对，将图像与文本映射到同一嵌入空间，实现概念跨模态语义对齐</li>
<li>特点：
<ul>
<li>图文关联弱，噪声较大</li>
<li>海量数据易获取</li>
<li>泛化能力强</li>
</ul>
</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/compare_learn.png" alt=""></p>
<h2 id="clip">CLIP</h2>
<ul>
<li>首个将Transformer、对比学习结合，从4亿互联网图文对数据集训练多模态图文匹配模型。</li>
<li></li>
</ul>
<h3 id="特点">特点</h3>
<ul>
<li>跨模态对齐</li>
<li>零样本预测能力</li>
<li>较强的泛化能力</li>
<li>大规模预训练</li>
</ul>
<h3 id="模型训练">模型训练</h3>
<ol>
<li>从数据集中选取Batch大小为N的图文对数据</li>
<li>分别经过图(Resnet or VIT)、文(Transformer)编码器转化成特征</li>
<li>学习图文多模态特征嵌入空间，使得可以在特征空间计算图文匹配相似性</li>
<li>计算两两图文之间的相似度，并用交叉熵函数(对称交叉熵)计算损失</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/clip.png" alt=""></p>
<h3 id="缺点">缺点</h3>
<ul>
<li>数据集需要大量人工清理(互联网上的数据可能包含噪声、错误或不准确的描述。为了确保模型能够学习到准确的视觉和语言关联，需要人工清理和验证数据集，确保图像和文本描述是准确匹配的。)</li>
</ul>
<h2 id="align">ALIGN</h2>
<h3 id="特点">特点</h3>
<ul>
<li>模型更大,需要更大数据集</li>
<li>采用自然图文对数据分布</li>
</ul>
<h2 id="预训练模型的迁移学习">预训练模型的迁移学习</h2>
<ul>
<li>在实际应用中,我们需要将预训练模型迁移至下游识别任务,但如果直接完全微调预训练视觉语言模型需要大量的数据和计算资源,所以对预训练模型的迁移学习的研究十分有必要,这里作者给出两个方向对模型进行迁移学习</li>
</ul>
<h3 id="提示学习">提示学习</h3>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/remind_learn.png" alt=""></p>
<h4 id="文本提示学习">文本提示学习</h4>
<h5 id="coop">CoOp</h5>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2109.01134">论文</a> <a target="_blank" rel="noopener" href="https://github.com/KaiyangZhou/CoOp">代码</a></p>
<h6 id="思想">思想</h6>
<ul>
<li>从手工提示进行改进,对提示模板进行学习,优化提示与句子之间的联系(将手工提示过程自动化)</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/CoOp.png" alt=""></p>
<h6 id="特点">特点</h6>
<ul>
<li>使用一组可学习向量(learnable context)对提示词中的上下文进行建模，在训练中使用分类损失进行向量优化</li>
<li>使用更少的计算资源、训练数据和训练时间优化匹配</li>
</ul>
<h6 id="缺点">缺点</h6>
<ul>
<li>可学习的上下文极大影响模型对于未知类预测的泛化性,学习到的固定提示会过拟合于特定的类别集合</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/dis_CoOp.png" alt=""></p>
<h5 id="cocoop">CoCoOp</h5>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.05557">论文</a> <a target="_blank" rel="noopener" href="https://github.com/KaiyangZhou/CoOp">代码</a></p>
<h6 id="思想">思想</h6>
<ul>
<li>使提示以每个输入实例（图像）为条件，动态预测，而非学习后固定</li>
<li>context tokens也可以由image embedding决定</li>
<li>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>m</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>v</mi><mi>m</mi></msub><mo>+</mo><mi>π</mi></mrow><annotation encoding="application/x-tex">v_m(x) = v_m + \pi 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.73333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">π</span></span></span></span></span></p>
</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/CoCoOp.png" alt=""></p>
<h6 id="特点">特点</h6>
<ul>
<li>提示学习过程以对应实例为条件，不影响未知类别，增强泛化性</li>
</ul>
<h5 id="cupl">CuPL</h5>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2209.03320v1">论文</a> <a target="_blank" rel="noopener" href="https://github.com/sarahpratt/CuPL">代码</a></p>
<h6 id="思想">思想</h6>
<ul>
<li>引入大语言模型的回答作为文本的prompt进行分类</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/CuPL.png" alt=""></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/CuPL_prompts.png" alt=""></p>
<h6 id="特点">特点</h6>
<ul>
<li>性能的提升随着使用的LLM提示和图像提示的增加而增大</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/LLM.png" alt=""></p>
<h4 id="视觉提示学习">视觉提示学习</h4>
<ul>
<li>在视觉主干网络（图像编码器）引入提示学习,优化图像特征</li>
</ul>
<h5 id="vpt">VPT</h5>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.12119">论文</a> <a target="_blank" rel="noopener" href="https://github.com/kmnp/vpt">代码</a></p>
<h6 id="思想">思想</h6>
<ul>
<li>图像Transformer编码层输入序列插入可学习提示参数</li>
<li>训练过程中冻结主干网络参数，只微调新增的提示参数</li>
</ul>
<h6 id="vpt-shallow">VPT-Shallow</h6>
<ul>
<li>只在第一个编码层插入提示</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/vpt-shallow-formula.png" alt=""></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/vpt-shallow.png" alt=""></p>
<h6 id="vpt-deep">VPT-Deep</h6>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2304.08386">论文</a></p>
<ul>
<li>在每一个编码层的输入序列插入提示</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/vpt-deep-formula.png" alt=""></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/vpt-deep.png" alt=""></p>
<h5 id="dam-vp">DAM-VP</h5>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.08138">论文</a> <a target="_blank" rel="noopener" href="https://github.com/shikiw/DAM-VP">代码</a></p>
<h6 id="思想">思想</h6>
<ul>
<li>数据集多样性感知提示策略，并使用元提示进行初始化</li>
<li>将下游数据集分成小的同质子集,并对每个子集分别优化</li>
</ul>
<h6 id="实现">实现</h6>
<ul>
<li>训练
<ul>
<li>给定下游数据集，随机选取一个子集输入无提示的模型提取特征，并执行聚类；类别数量由预定义阈值根据多样性程度定义。每个聚簇对应一个视觉提示</li>
</ul>
</li>
<li>测试
<ul>
<li>使用无提示模型生成特征并寻找聚类中心，获得对应的提示进行推理</li>
</ul>
</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/dam-vp.png" alt=""></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/DAM-VP-f.png" alt=""></p>
<h4 id="多模态提示学习">多模态提示学习</h4>
<h5 id="maple">MaPLe</h5>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2210.03117">论文</a> <a target="_blank" rel="noopener" href="https://github.com/muzairkhattak/multimodal-prompt-learning">代码</a></p>
<h6 id="思想">思想</h6>
<ul>
<li>在文本和图像编码器的前J层（总层数为K）分别加上额外可学习提示，剩下K-J层的提示编码来自上一层的输出。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/maple.png" alt=""></p>
<h6 id="特点">特点</h6>
<ul>
<li>引入使用J个耦合函数（线性层）将文本提示转换为视觉提示，即视觉提示由文本提示生成</li>
<li>共享可学习嵌入空间，促进模态间协同优化</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/maple-formula.png" alt=""></p>
<h3 id="特征适配器">特征适配器</h3>
<h4 id="clip-adapter">CLIP-adapter</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2110.04544">论文</a> <a target="_blank" rel="noopener" href="https://github.com/gaopengcuhk/clip-adapter">代码</a></p>
<h5 id="思想">思想</h5>
<ul>
<li>只微调额外添加的轻量特征适配器，该适配器通常被加在文本和视觉编码器之后</li>
</ul>
<h5 id="特点">特点</h5>
<ul>
<li>与CoOp相比
<ul>
<li>CoOp: 可学习的提示置于文本或视觉编码器之前， 需要正向和反向传播文本/图像编码器梯度</li>
<li>CLIP-adapter: 特征适配器置于文本与视觉编码器之后，不需要传播编码器的梯度，提升优化效率</li>
</ul>
</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/clip-adapter.png" alt=""></p>
<h5 id="结构">结构</h5>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/clip-ada.png" alt=""></p>
<ul>
<li>双层感知机</li>
<li>残差融合<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/adapter-formula.png" alt=""><br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/adapter-formula-f.png" alt=""></li>
</ul>
<h4 id="etris">ETRIS</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2209.00068">论文</a> <a target="_blank" rel="noopener" href="https://github.com/kkakkkka/ETRIS">代码</a></p>
<h5 id="思想">思想</h5>
<ul>
<li>设计新的桥接器模块可以无缝集成到经典的双编码器视觉语言预训练模型以增强跨模态融合（通用、兼容）。</li>
<li>设计轻量化的解码器，实现视觉语言特征的多尺度对齐。</li>
</ul>
<h5 id="实现">实现</h5>
<ul>
<li>Bridger：包含Zoom Layer调节特征尺寸，所得特征输入交互器进行融合</li>
<li>Zoom Layer：卷积和反卷积</li>
<li>交互器：自注意力模块和交叉注意力模块</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/ETRIS.png" alt=""></p>
<h4 id="tip-adapter">TIP-adapter</h4>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2111.03930">论文</a> <a target="_blank" rel="noopener" href="https://github.com/gaopengcuhk/Tip-Adapter">代码</a></p>
<h5 id="思想">思想</h5>
<ul>
<li>探索一种无需训练的模型迁移范式</li>
<li>基于小样本数据集设计查询-键值缓存来实现</li>
</ul>
<h5 id="实现">实现</h5>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/TIP-ADAPTER.png" alt=""></p>
<ul>
<li>将小样本图像的CLIP视觉编码器特征作为缓存中的key，将对应类别标签作为Value存储。</li>
<li>推理阶段，获取图像CLIP视觉编码器特征作为Query，生成对应的关系向量：<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/tip-adapter-f1.png" alt=""></li>
<li>图像分类预测由关系向量A和Value的点积及CLIP分类器的结果加权：<br>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/tip-adapter-f2.png" alt=""></li>
</ul>
<h4 id="tip-adapter-f">TIP-adapter-F</h4>
<h5 id="思想">思想</h5>
<ul>
<li>针对TIP-adapter做出改进,将缓存设置为可学习向量，并用原本的OneHot向量作为初始化，微调提升性能</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/tip-adapter-f.png" alt=""></p>
<h1 id="开放词汇检测">开放词汇检测</h1>
<ul>
<li>学习范式：从自然图文对数据中获取开放类别知识，从区域级监督数据中学习目标检测</li>
</ul>
<h2 id="数据增广">数据增广</h2>
<h3 id="ovr-cnn">OVR-CNN</h3>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9577418">论文</a> <a target="_blank" rel="noopener" href="https://github.com/alirezazareian/ovr-cnn">代码</a></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/ovr-cnn.png" alt=""></p>
<h4 id="思想">思想</h4>
<ul>
<li>
<p>Learning Visual Semantic Space:</p>
<ul>
<li>利用image-caption数据预训练backbone以获取开放词汇知识</li>
</ul>
</li>
<li>
<p>Learning Open-Vocabulary Detection:</p>
<ul>
<li>利用目标检测监督数据微调检测模型</li>
</ul>
</li>
</ul>
<h4 id="实现">实现</h4>
<h5 id="pre-training">Pre-training</h5>
<ul>
<li>Image (w*h)输入resnet50 backbone，提取区域的视觉特征(w/32*h/32)，并使用全连接层 (V2L) 将其转换到文本特征空间</li>
<li>基于Caption提取文本特征。视觉特征与文本特征间计算弱监督形式的Grounding Loss</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/ovr-cnn-pre.png" alt=""></p>
<h5 id="detection-training">Detection Training</h5>
<ul>
<li>基于预训练的backbone，V2L层与embedding层构建检测器</li>
<li>利用仅包含基础类的物体检测数据集对检测器进行监督训练</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/ovr-cnn-detec.png" alt=""></p>
<h3 id="regionclip">RegionCLIP</h3>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2112.09106">论文</a> <a target="_blank" rel="noopener" href="https://github.com/microsoft/RegionCLIP">代码</a></p>
<ul>
<li>CLIP 模型的训练是使用整个image作为输入的，使用的是image-level的文本描述来训练的，所以，模型学习到的是整张图的特征</li>
<li>这种模型无法将文本概念和图像中的区域联系起来</li>
</ul>
<h4 id="思想">思想</h4>
<ul>
<li>借助CLIP模型进行区域级图文匹配预训练</li>
</ul>
<h4 id="实现">实现</h4>
<ul>
<li>利用RCN构造region伪标签与image-text 一起预训练</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/region-clip.png" alt=""></p>
<h3 id="glip">GLIP</h3>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.03857">论文</a> <a target="_blank" rel="noopener" href="https://github.com/microsoft/GLIP">代码</a></p>
<h4 id="思想">思想</h4>
<ul>
<li>将物体匹配与短语定位任务统一起来进行预训练</li>
<li>利用区域定位能力从图文对数据中构建准确的区域文本对数据</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/glip.png" alt=""></p>
<h4 id="实现">实现</h4>
<ul>
<li>利用已有的Grounding数据（80万）进行监督训练，得到教师模型</li>
<li>从图像文本对数据提取名词短语，基于“教师-学生”半监督学习从“图像文本对”生成“区域文本对”伪标签，并加入训练学生模型。</li>
</ul>
<h3 id="grounding-dino">Grounding-DINO</h3>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2303.05499v4">论文</a> <a target="_blank" rel="noopener" href="https://github.com/IDEA-Research/GroundingDINO">代码</a></p>
<ul>
<li>更强的检测器架构：基于Transformer Detector DINO进行预训练</li>
<li>更细粒度的多模态特征融合：特征编码、query初始化、特征解码三个层面的特征融合</li>
<li>更强的Grounding能力：支持Referring Expression Comprehension（REC）</li>
</ul>
<h4 id="特点">特点</h4>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/grouding-dino-featrues.png" alt=""></p>
<h3 id="vl-plm">VL-PLM</h3>
<h4 id="思想">思想</h4>
<ul>
<li>借助视觉语言预训练模型为无标注图像构造“区域-文本”伪标签，训练物体检测器</li>
</ul>
<h4 id="实现">实现</h4>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/vl-plm.png" alt=""></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/vl-plm-tag.png" alt=""></p>
<h3 id="marvelovd">MarvelOVD</h3>
<h4 id="思想">思想</h4>
<ul>
<li>弥补视觉语言模型在区域推理中由于领域差异造成的噪声标签问题（伪标签不准确）</li>
<li>检测器具备上下文特征提取能力与背景概念，动态结合检测器性质以弥补领域差异</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/marvalovd-think.png" alt=""></p>
<h4 id="实现">实现</h4>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/marvalovd-1.png" alt=""></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/marvalovd-2.png" alt=""></p>
<h3 id="generateu">GenerateU</h3>
<h2 id="迁移学习">迁移学习</h2>
<h3 id="vild">ViLD</h3>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2104.13921">论文</a></p>
<h4 id="思想">思想</h4>
<ul>
<li>基于标注框及RPN生成的检测框截取局部图像，输入CLIP 图像编码器提取视觉表征</li>
<li>添加L1损失，使检测器的ROI特征对齐CLIP特征</li>
<li>对齐特征既包括基础类别，也包括图像中潜在的开放类别物体</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/vild-think.png" alt=""></p>
<h4 id="实现">实现</h4>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="../images/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/vild.png" alt=""></p>
<h3 id="lbp">LBP</h3>
<h4 id="思想">思想</h4>
<ul>
<li>提出针对背景框更好的表征学习方案，挖掘潜在开放类别</li>
</ul>
<h3 id="f-vlm">F-VLM</h3>
<h1 id="开放词汇分割">开放词汇分割</h1>
<h1 id="下游任务应用">下游任务应用</h1>
<h1 id="多模态大模型">多模态大模型</h1>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">听灵</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/05/28/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/">http://example.com/2024/05/28/%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E8%A7%86%E8%A7%89%E6%84%9F%E7%9F%A5/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">半夏琉璃空</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/">深度学习|计算机视觉|多模态大模型</a></div><div class="post_share"><div class="social-share" data-image="https://ts1.cn.mm.bing.net/th/id/R-C.ee3ad0b69428b46be2c9e30317db058f?rik=JV94iKBiuWCNJg&amp;riu=http%3a%2f%2fpic.bizhi360.com%2fbbpic%2f27%2f2727.jpg&amp;ehk=c2AYatSYzhHx3oUBzqSvzhTD62o7hz6mF5TBHt4nlQ8%3d&amp;risl=&amp;pid=ImgRaw&amp;r=0" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/06/06/%E7%AE%80%E5%8D%95%E7%9A%84%E5%9F%BA%E4%BA%8ELinux%E7%9A%84web%E6%9C%8D%E5%8A%A1%E5%99%A8/" title="简单的基于Linux的web服务器"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ts1.cn.mm.bing.net/th/id/R-C.f595c3bc51b09f7c2224e71d9f9ad54e?rik=3mVI4RN%2bX0t9pQ&amp;riu=http%3a%2f%2ffunpicimg.loveinhere.com%2f1006%2f3%2f10534.jpg&amp;ehk=hfmcsU27D56x0NFQHKHL36A0A%2fvNru2U76QRmZYlhzc%3d&amp;risl=&amp;pid=ImgRaw&amp;r=0" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">简单的基于Linux的web服务器</div></div></a></div><div class="next-post pull-right"><a href="/2024/03/20/C/" title="C++"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ts1.cn.mm.bing.net/th/id/R-C.ee3ad0b69428b46be2c9e30317db058f?rik=JV94iKBiuWCNJg&amp;riu=http%3a%2f%2fpic.bizhi360.com%2fbbpic%2f27%2f2727.jpg&amp;ehk=c2AYatSYzhHx3oUBzqSvzhTD62o7hz6mF5TBHt4nlQ8%3d&amp;risl=&amp;pid=ImgRaw&amp;r=0" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">C++</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/06/06/clip/" title="clip"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ts1.cn.mm.bing.net/th/id/R-C.f595c3bc51b09f7c2224e71d9f9ad54e?rik=3mVI4RN%2bX0t9pQ&riu=http%3a%2f%2ffunpicimg.loveinhere.com%2f1006%2f3%2f10534.jpg&ehk=hfmcsU27D56x0NFQHKHL36A0A%2fvNru2U76QRmZYlhzc%3d&risl=&pid=ImgRaw&r=0" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-06</div><div class="title">clip</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/images/%E7%AB%A5%E5%BF%83%E4%B9%8B%E4%B9%A6.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">听灵</div><div class="author-info__description">Journey of a thousand miles begins with single step</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/baiyue49"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/baiyue49" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:2082973145@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">背景介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#open-set-recognition"><span class="toc-number">1.1.</span> <span class="toc-text">open-Set Recognition</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#few-shot-learning"><span class="toc-number">1.2.</span> <span class="toc-text">Few-Shot Learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#zero-shot-learning"><span class="toc-number">1.3.</span> <span class="toc-text">Zero-Shot Learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#open-vocabulary-learning"><span class="toc-number">1.4.</span> <span class="toc-text">Open Vocabulary Learning</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E5%88%86%E7%B1%BB"><span class="toc-number">2.</span> <span class="toc-text">开放词汇分类</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#clip"><span class="toc-number">2.1.</span> <span class="toc-text">CLIP</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E7%82%B9"><span class="toc-number">2.1.1.</span> <span class="toc-text">特点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">2.1.2.</span> <span class="toc-text">模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-number">2.1.3.</span> <span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#align"><span class="toc-number">2.2.</span> <span class="toc-text">ALIGN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E7%82%B9"><span class="toc-number">2.2.1.</span> <span class="toc-text">特点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.3.</span> <span class="toc-text">预训练模型的迁移学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.3.1.</span> <span class="toc-text">提示学习</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%87%E6%9C%AC%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.3.1.1.</span> <span class="toc-text">文本提示学习</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#coop"><span class="toc-number">2.3.1.1.1.</span> <span class="toc-text">CoOp</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">2.3.1.1.1.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%89%B9%E7%82%B9"><span class="toc-number">2.3.1.1.1.2.</span> <span class="toc-text">特点</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-number">2.3.1.1.1.3.</span> <span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#cocoop"><span class="toc-number">2.3.1.1.2.</span> <span class="toc-text">CoCoOp</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">2.3.1.1.2.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%89%B9%E7%82%B9"><span class="toc-number">2.3.1.1.2.2.</span> <span class="toc-text">特点</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#cupl"><span class="toc-number">2.3.1.1.3.</span> <span class="toc-text">CuPL</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">2.3.1.1.3.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%89%B9%E7%82%B9"><span class="toc-number">2.3.1.1.3.2.</span> <span class="toc-text">特点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%86%E8%A7%89%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.3.1.2.</span> <span class="toc-text">视觉提示学习</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#vpt"><span class="toc-number">2.3.1.2.1.</span> <span class="toc-text">VPT</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">2.3.1.2.1.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#vpt-shallow"><span class="toc-number">2.3.1.2.1.2.</span> <span class="toc-text">VPT-Shallow</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#vpt-deep"><span class="toc-number">2.3.1.2.1.3.</span> <span class="toc-text">VPT-Deep</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#dam-vp"><span class="toc-number">2.3.1.2.2.</span> <span class="toc-text">DAM-VP</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">2.3.1.2.2.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.3.1.2.2.2.</span> <span class="toc-text">实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.3.1.3.</span> <span class="toc-text">多模态提示学习</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#maple"><span class="toc-number">2.3.1.3.1.</span> <span class="toc-text">MaPLe</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">2.3.1.3.1.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%89%B9%E7%82%B9"><span class="toc-number">2.3.1.3.1.2.</span> <span class="toc-text">特点</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%80%82%E9%85%8D%E5%99%A8"><span class="toc-number">2.3.2.</span> <span class="toc-text">特征适配器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#clip-adapter"><span class="toc-number">2.3.2.1.</span> <span class="toc-text">CLIP-adapter</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">2.3.2.1.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%89%B9%E7%82%B9"><span class="toc-number">2.3.2.1.2.</span> <span class="toc-text">特点</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BB%93%E6%9E%84"><span class="toc-number">2.3.2.1.3.</span> <span class="toc-text">结构</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#etris"><span class="toc-number">2.3.2.2.</span> <span class="toc-text">ETRIS</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">2.3.2.2.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.3.2.2.2.</span> <span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tip-adapter"><span class="toc-number">2.3.2.3.</span> <span class="toc-text">TIP-adapter</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">2.3.2.3.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.3.2.3.2.</span> <span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tip-adapter-f"><span class="toc-number">2.3.2.4.</span> <span class="toc-text">TIP-adapter-F</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">2.3.2.4.1.</span> <span class="toc-text">思想</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E6%A3%80%E6%B5%8B"><span class="toc-number">3.</span> <span class="toc-text">开放词汇检测</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%B9%BF"><span class="toc-number">3.1.</span> <span class="toc-text">数据增广</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ovr-cnn"><span class="toc-number">3.1.1.</span> <span class="toc-text">OVR-CNN</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">3.1.1.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.1.1.2.</span> <span class="toc-text">实现</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#pre-training"><span class="toc-number">3.1.1.2.1.</span> <span class="toc-text">Pre-training</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#detection-training"><span class="toc-number">3.1.1.2.2.</span> <span class="toc-text">Detection Training</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#regionclip"><span class="toc-number">3.1.2.</span> <span class="toc-text">RegionCLIP</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">3.1.2.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.1.2.2.</span> <span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#glip"><span class="toc-number">3.1.3.</span> <span class="toc-text">GLIP</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">3.1.3.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.1.3.2.</span> <span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#grounding-dino"><span class="toc-number">3.1.4.</span> <span class="toc-text">Grounding-DINO</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E7%82%B9"><span class="toc-number">3.1.4.1.</span> <span class="toc-text">特点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#vl-plm"><span class="toc-number">3.1.5.</span> <span class="toc-text">VL-PLM</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">3.1.5.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.1.5.2.</span> <span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#marvelovd"><span class="toc-number">3.1.6.</span> <span class="toc-text">MarvelOVD</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">3.1.6.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.1.6.2.</span> <span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#generateu"><span class="toc-number">3.1.7.</span> <span class="toc-text">GenerateU</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0"><span class="toc-number">3.2.</span> <span class="toc-text">迁移学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#vild"><span class="toc-number">3.2.1.</span> <span class="toc-text">ViLD</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">3.2.1.1.</span> <span class="toc-text">思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.2.1.2.</span> <span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lbp"><span class="toc-number">3.2.2.</span> <span class="toc-text">LBP</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%9D%E6%83%B3"><span class="toc-number">3.2.2.1.</span> <span class="toc-text">思想</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#f-vlm"><span class="toc-number">3.2.3.</span> <span class="toc-text">F-VLM</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%80%E6%94%BE%E8%AF%8D%E6%B1%87%E5%88%86%E5%89%B2"><span class="toc-number">4.</span> <span class="toc-text">开放词汇分割</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%8B%E6%B8%B8%E4%BB%BB%E5%8A%A1%E5%BA%94%E7%94%A8"><span class="toc-number">5.</span> <span class="toc-text">下游任务应用</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.</span> <span class="toc-text">多模态大模型</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2024 By 听灵</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="/js/tw_cn.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.8/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script defer src="/js/cursor.js"></script><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="30" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>